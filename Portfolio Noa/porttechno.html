<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="portcss.css" />
    <link
      rel="stylesheet"
      media="screen"
      href="https://fontlibrary.org//face/clayborn"
      type="text/css"
    />
    <link
      rel="stylesheet"
      media="screen"
      href="https://fontlibrary.org//face/karla-bold-stencil"
      type="text/css"
    />
    <link
      rel="stylesheet"
      media="screen"
      href="https://fontlibrary.org//face/russisch-sans"
      type="text/css"
    />
    <link href="https://css.gg/arrow-right-o.css" rel="stylesheet" />
    <link
      href="https://unpkg.com/css.gg@2.0.0/icons/css/shape-circle.css"
      rel="stylesheet"
    />
    <link
      href="https://unpkg.com/css.gg@2.0.0/icons/css/radio-check.css"
      rel="stylesheet"
    />
    <link
      href="https://unpkg.com/css.gg@2.0.0/icons/css/arrow-right-o.css"
      rel="stylesheet"
    />
    <link rel="icon" href="Portlogo.png" />
    <title>Portfolio Noa</title>
  </head>
  <body>
    <section id="navbar">
      <div class="navclass">
        <a href="porthome.html"><img src="Portlogo.png" alt="" /></a>
        <div class="navli">
          <a href="portabout.html"><li>About</li></a>
          <a href="portprojets.html"><li>Projects</li></a>
          <a href="porttechno.html"><li>Veille Techno</li></a>
          <a href="portdoc.html"><li>Documentation</li></a>
        </div>
      </div>
    </section>

    <section id="navx">
      <div class="abt">
        <h1>Veille techno : les BOTS</h1>
        <div class="webh2">
          <i class="gg-shape-circle"></i>
          <h2>Définition:</h2>
        </div>
        <div class="scolaire">
          <p>
            Les bots sont des programmes informatiques conçus pour effectuer
            automatiquement des tâches sur Internet, souvent en imitant le
            comportement humain. Ils sont largement utilisés dans divers
            domaines, tels que les réseaux sociaux, le service client et le
            commerce électronique. <br />
            <br />Il existe plusieurs type de bots:
          </p>
        </div>
        <div class="scolaire">
          <img src="bots copy.jpg" alt="" />
        </div>
        <div class="webh2">
          <i class="gg-shape-circle"></i>
          <h2>Chatbox:</h2>
        </div>
        <div class="scolaire">
          <p>
            Les chatbots sont des programmes informatiques conçus pour simuler
            une conversation humaine via des interfaces de chat. Ils sont
            utilisés dans divers contextes, tels que le service client, le
            support technique et le marketing, pour fournir des réponses
            automatisées aux utilisateurs.
          </p>
        </div>
        <div class="webh2">
          <i class="gg-shape-circle"></i>
          <h2>Spambox:</h2>
        </div>
        <div class="scolaire">
          <p>
            Les spambots sont des logiciels automatisés qui parcourent Internet
            à la recherche d'adresses électroniques ou de forums en ligne pour y
            envoyer des messages indésirables. Leur objectif principal est de
            propager du contenu non sollicité, comme des publicités, des
            escroqueries ou des logiciels malveillants, souvent de manière
            massive. Leur présence peut perturber les communications en ligne,
            entraînant une surcharge de boîtes de réception et la propagation de
            fausses informations. Les utilisateurs doivent souvent recourir à
            des outils de filtrage ou de protection contre les spams pour
            contrer ces activités nuisibles.
          </p>
        </div>
        <div class="webh2">
          <i class="gg-shape-circle"></i>
          <h2>Scraping bots:</h2>
        </div>
        <div class="scolaire">
          <p>
            Les scraping bots, également appelés web scrapers, sont des
            programmes automatisés conçus pour extraire des données spécifiques
            à partir de sites web. Ils parcourent les pages web de manière
            systématique, collectant des informations telles que des prix de
            produits, des avis d'utilisateurs ou des données de marché. Bien
            qu'ils puissent être utilisés à des fins légitimes telles que la
            collecte de données pour la recherche ou l'analyse concurrentielle,
            ils peuvent également être exploités pour des activités illégales
            telles que le vol de contenu protégé par des droits d'auteur ou le
            spam. Les propriétaires de sites web utilisent souvent des mesures
            de protection telles que des techniques anti-scraping ou des
            fichiers robots.txt pour restreindre l'accès des scraping bots à
            leur contenu.
          </p>
        </div>
        <div class="aboutprelink">
          <a id="stopspin" href="portprojets.html">Voir les autres projets</a>
          <span><i id="iconspin" class="gg-arrow-right-o"></i></span>
        </div>
      </div>
    </section>
    <script src="portjsweb.js"></script>
  </body>
</html>
